{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhBfwzBgioTD"
   },
   "source": [
    "**Data about passengers:**\n",
    "*   Name\n",
    "*   Age\n",
    "*   Gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIEH8iZqi-sk"
   },
   "source": [
    "## Install and Import Libraries\n",
    "Let's install PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj1HhvIOY5Yz",
    "outputId": "74bed871-444b-418e-c526-d6fc1231cc50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 212.4 MB 58 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 52.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=c69a1705b3d88ea639859e4e09b21f959476c899eebdc65ceda68c9ff7388653\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
    "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark                                                                            \n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
    "!pip install findspark                                                                            \n",
    "!pip install pyspark                                                                            \n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDp80mG9jmfU"
   },
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttzML9fpjE5a"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx2qAccBk15y"
   },
   "outputs": [],
   "source": [
    "train = spark.read.csv('train.csv', header=True,inferSchema=True)\n",
    "test = spark.read.csv('test.csv', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2ANTnWmSCq"
   },
   "source": [
    "Let's work with train dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5mWJR30lNs5"
   },
   "source": [
    "**Confirm if this is a dataframe or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEYTePrzk9yl",
    "outputId": "daee6ab7-307e-44ba-bb42-319ec5b4b8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvLJElPrlT4i"
   },
   "source": [
    "**Show 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYwhqvV8lnO0",
    "outputId": "ec89eb00-ef50-4f9d-cc43-00fc46b153e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=2, Survived=1, Pclass=1, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Sex='female', Age=38.0, SibSp=1, Parch=0, Ticket='PC 17599', Fare=71.2833, Cabin='C85', Embarked='C'),\n",
       " Row(PassengerId=3, Survived=1, Pclass=3, Name='Heikkinen, Miss. Laina', Sex='female', Age=26.0, SibSp=0, Parch=0, Ticket='STON/O2. 3101282', Fare=7.925, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=4, Survived=1, Pclass=1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Sex='female', Age=35.0, SibSp=1, Parch=0, Ticket='113803', Fare=53.1, Cabin='C123', Embarked='S'),\n",
       " Row(PassengerId=5, Survived=0, Pclass=3, Name='Allen, Mr. William Henry', Sex='male', Age=35.0, SibSp=0, Parch=0, Ticket='373450', Fare=8.05, Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QIYVxRXlnnw"
   },
   "source": [
    "**Display schema for the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcvERiICl1Ep",
    "outputId": "26e0e106-6644-46c2-e3ba-f30328027ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmE3Wd80l1S6"
   },
   "source": [
    "**Statistical summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNY0SItol5Mo",
    "outputId": "d123a60f-1e60-448a-8989-8e40f0db2c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiFaIEQTl70_"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSNPOnP8mw2Q"
   },
   "source": [
    "**Display count for the train dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrtpG11Fl9HM",
    "outputId": "ba11281e-ff8a-49eb-f981-3cbac3bc6414"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_6nnTfxm9_x"
   },
   "source": [
    "**Can you answer this question:** \n",
    "\n",
    "**How many people survived, and how many didn't survive?** \n",
    "\n",
    "**Please save data in a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W208jclJNmpS",
    "outputId": "f88c1861-1158-4da8-e1af-ebbd1564a7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Survived|\n",
      "+--------+\n",
      "|       0|\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "|       1|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       1|\n",
      "|       0|\n",
      "|       1|\n",
      "|       0|\n",
      "|       1|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('Survived').show()\n",
    "survived = train.filter('Survived=1').count()\n",
    "not_survived = train.filter('Survived=0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8DUtZXPn46m"
   },
   "source": [
    "**Display your result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XHAK8ceoCMU",
    "outputId": "60158db5-60ca-4d0f-c222-61de5392a88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "print(survived)\n",
    "print(not_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygsg7wQqor9a"
   },
   "source": [
    "**Can you display your answer in ratio form?(Hint: Use UDF.)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uiaN29PoQnf"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "def ratio (x):\n",
    "    \n",
    "     return f.udf(lambda col: col/x, FloatType())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvzEwesgoQ3s",
    "outputId": "dac2202a-1d2c-470b-a889-6e125613af72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+\n",
      "|Survived|count|     Ratio|\n",
      "+--------+-----+----------+\n",
      "|       1|  342| 0.3838384|\n",
      "|       0|  549|0.61616164|\n",
      "+--------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('Survived').groupby('Survived').count().withColumn('Ratio', ratio(train.count())('count')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Aker_lp1h4"
   },
   "source": [
    "**Can you get the number of males and females?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XllkDlo3ongJ",
    "outputId": "6afb1aad-ec72-4bed-a7f4-a6e84d31dffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('Sex').groupby('Sex').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFaJ15zqtEV"
   },
   "source": [
    "**1. What is the average number of survivors of each gender?**\n",
    "\n",
    "**2. What is the number of survivors of each gender?**\n",
    "\n",
    "(Hint: Group by the \"sex\" column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUikH7MUqdKq",
    "outputId": "f9452bc2-da0b-4086-cf27-ecede46a1aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----------+\n",
      "|Survived|   Sex|count|     Ratio|\n",
      "+--------+------+-----+----------+\n",
      "|       1|  male|  109|0.31871346|\n",
      "|       1|female|  233| 0.6812866|\n",
      "+--------+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.filter('Survived=1').groupBy('Survived','Sex').count().withColumn('Ratio', ratio(train.filter('Survived=1').count())('count')).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s38PhSFEcWwQ",
    "outputId": "362d6484-ae21-4fa8-cc9d-593cd56b31fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|Survived|   Sex|count|\n",
      "+--------+------+-----+\n",
      "|       0|female|   81|\n",
      "|       1|  male|  109|\n",
      "|       1|female|  233|\n",
      "|       0|  male|  468|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('Survived','Sex').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCEdYNdArtRN"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "**Create temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjlK6HDUqsI5"
   },
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView(\"TrainData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNePifnshHr"
   },
   "source": [
    "**How many people survived, and how many didn't survive? By SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HxfPRTMslqk",
    "outputId": "49a660c5-6d6b-4724-ea8d-cbfad6464d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|Survived|count(Survived)|\n",
      "+--------+---------------+\n",
      "|       1|            342|\n",
      "|       0|            549|\n",
      "+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(''' SELECT Survived,count(Survived)\n",
    "From TrainData\n",
    "group by Survived ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVCdY6EasFWV"
   },
   "source": [
    "**Can you display the number of survivors from each gender as a ratio?**\n",
    "\n",
    "(Hint: Group by \"sex\" column.)\n",
    "\n",
    "**Can you do this via SQL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xQc3pUUr3HF",
    "outputId": "6abc5972-13f1-4cc0-c720-1bee23ab762a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------+\n",
      "|   Sex|count(Sex)|      avg(Survived)|\n",
      "+------+----------+-------------------+\n",
      "|female|       314| 0.7420382165605095|\n",
      "|  male|       577|0.18890814558058924|\n",
      "+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(''' SELECT Sex,count(Sex),avg(Survived)\n",
    "From TrainData\n",
    "group by Sex''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QXc5V8uu3Y"
   },
   "source": [
    "**Display a ratio for p-class:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mscs2mDFdFsD",
    "outputId": "9255f822-4c5c-4bec-ce39-af3a7c2d1612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------------------------------------------+\n",
      "|Pclass|Each_Class|(CAST(count(Pclass) AS DOUBLE) / CAST(891 AS DOUBLE))|\n",
      "+------+----------+-----------------------------------------------------+\n",
      "|     1|       216|                                  0.24242424242424243|\n",
      "|     3|       491|                                   0.5510662177328844|\n",
      "|     2|       184|                                  0.20650953984287318|\n",
      "+------+----------+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(''' SELECT Pclass,count(Pclass) Each_Class , count(Pclass)/891\n",
    "From TrainData\n",
    "group by Pclass''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0klxwAvg6J"
   },
   "source": [
    "**Let's take a break and continue after this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ctM9t8atxJl"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CfanZTCt6Wk"
   },
   "source": [
    "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Nm8S1K0r4uY"
   },
   "outputs": [],
   "source": [
    "df = train.union(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI7AD8FLz3iO"
   },
   "source": [
    "**Display count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4rd9e6nzzr5",
    "outputId": "64e73ada-4858-4fca-c8a8-0fe19e66a100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVQlr9vDy7Y4"
   },
   "source": [
    "**Temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_WERAL8wvJa"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R4Miuy0z_uP"
   },
   "source": [
    "**Can you define the number of null values in each column?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LMOalKBxhpD",
    "outputId": "3f5a9412-aace-4b80-c25c-093020e8ac73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBX8cJ000aqe"
   },
   "source": [
    "**Create Dataframe for null values**\n",
    "\n",
    "1. Column\n",
    "2. Number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITmyUelNxjJM",
    "outputId": "1735232e-0e24-40a2-d45b-550c4aa8ce01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new= df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKrOi5a0-Ma"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txa8NZIO1JaP"
   },
   "source": [
    "**Can you show me the name column from your temporary table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7yXqJoJy35k",
    "outputId": "4858bdc8-3469-4af7-8c68-f4bf11fd4bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "|    Moran, Mr. James|\n",
      "|McCarthy, Mr. Tim...|\n",
      "|Palsson, Master. ...|\n",
      "|Johnson, Mrs. Osc...|\n",
      "|Nasser, Mrs. Nich...|\n",
      "|Sandstrom, Miss. ...|\n",
      "|Bonnell, Miss. El...|\n",
      "|Saundercock, Mr. ...|\n",
      "|Andersson, Mr. An...|\n",
      "|Vestrom, Miss. Hu...|\n",
      "|Hewlett, Mrs. (Ma...|\n",
      "|Rice, Master. Eugene|\n",
      "|Williams, Mr. Cha...|\n",
      "|Vander Planke, Mr...|\n",
      "|Masselmani, Mrs. ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT Name from dataframe ''' ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F0F9cTZ2Cuz"
   },
   "source": [
    "**Run this code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kx6OcB-2BBT"
   },
   "outputs": [],
   "source": [
    "combined = df.withColumn('Title',f.regexp_extract(f.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "combined.createOrReplaceTempView('combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbZeUWS12r59"
   },
   "source": [
    "**Display the title and count \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGkFMtlp1FAI",
    "outputId": "72cf2f1c-94fc-41c6-eb5c-72f9e1ce80ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   Title|count(Title)|\n",
      "+--------+------------+\n",
      "|     Don|           1|\n",
      "|    Miss|         257|\n",
      "|Countess|           2|\n",
      "|     Col|           4|\n",
      "|     Rev|           9|\n",
      "|    Lady|           2|\n",
      "|  Master|          56|\n",
      "|     Mme|           1|\n",
      "|    Capt|           2|\n",
      "|      Mr|         786|\n",
      "|      Dr|          11|\n",
      "|     Mrs|         186|\n",
      "|     Sir|           2|\n",
      "|Jonkheer|           2|\n",
      "|    Mlle|           4|\n",
      "|   Major|           3|\n",
      "|      Ms|           1|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(''' SELECT Title ,count(Title) \n",
    "FROM combined\n",
    "group by Title ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBQDKYu4JOa"
   },
   "source": [
    "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rve4HffgDBkp"
   },
   "outputs": [],
   "source": [
    "titles_map = {'Mr':'not rare','Mrs':'not rare','Miss':'not rare','Master':'not rare','Dr':'rare', 'Rev':'rare', 'Major':'rare', 'Col':'rare', 'Mlle':'rare', 'Capt':'rare', 'Don':'rare', 'Jonkheer':'rare', 'Countess':'rare', 'Ms':'rare', 'Sir':'rare', 'Lady':'rare', 'Mme':'rare'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wrE95Cv7Oqh"
   },
   "source": [
    "**Run the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdDbWuDl7Pf4"
   },
   "outputs": [],
   "source": [
    "def impute_title(title):\n",
    "    return titles_map[title]\n",
    "\n",
    "udf_new=udf(lambda x: impute_title(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5EQVIhK7a9R"
   },
   "source": [
    "**Apply the function on \"Title\" column using UDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBAiIOn77XFa"
   },
   "outputs": [],
   "source": [
    "\n",
    "new_df=combined.withColumn('New_Titles',udf_new(f.col('Title')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8ewllf7kiV"
   },
   "source": [
    "**Display \"Title\" from table and group by \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9sjQb084GU6",
    "outputId": "91cab257-30c2-48ea-cbf5-3bae68b6ff01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|New_Titles|count|\n",
      "+----------+-----+\n",
      "|      rare|   44|\n",
      "|  not rare| 1285|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select('New_Titles').groupBy('New_Titles').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H45QNLj9vJp"
   },
   "source": [
    "## **Preprocessing Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwRAhumK-u__"
   },
   "source": [
    "**Based on the age mean, you will fill in the missing age values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXYSVzvl4z63",
    "outputId": "df09ec13-7d92-45b2-b055-f6d48cb0de7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.079501879699244\n"
     ]
    }
   ],
   "source": [
    "mean_age = new_df.select(f.mean(col('Age')).alias('mean')).collect()\n",
    "mean = mean_age[0]['mean']\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPivde8_GI-"
   },
   "source": [
    "**Fill missing age with age mean:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBgW8aFD90PA"
   },
   "outputs": [],
   "source": [
    "new_df1=new_df.na.fill(value=mean,subset=[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnlkI0nrJB91",
    "outputId": "6c4d32d5-93d6-4e6c-9ee8-19f909b74376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|               Age|\n",
      "+------------------+\n",
      "|              22.0|\n",
      "|              38.0|\n",
      "|              26.0|\n",
      "|              35.0|\n",
      "|              35.0|\n",
      "|30.079501879699244|\n",
      "|              54.0|\n",
      "|               2.0|\n",
      "|              27.0|\n",
      "|              14.0|\n",
      "|               4.0|\n",
      "|              58.0|\n",
      "|              20.0|\n",
      "|              39.0|\n",
      "|              14.0|\n",
      "|              55.0|\n",
      "|               2.0|\n",
      "|30.079501879699244|\n",
      "|              31.0|\n",
      "|30.079501879699244|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df1.select('Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGsnUz-m_P95"
   },
   "source": [
    "## **Preprocessing Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHbbamcXMSYP"
   },
   "source": [
    "**Select Embarked, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-lRu5vc_FW7"
   },
   "outputs": [],
   "source": [
    "grouped_Embarked=new_df1.select('Embarked').groupBy('Embarked').count().orderBy('count',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1qf5u2IOQrx"
   },
   "source": [
    "**Show groupped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSFNDTNg_erb",
    "outputId": "c7b43dc2-76c6-480c-ba8a-15bea8d2dc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  962|\n",
      "|       C|  253|\n",
      "|       Q|  111|\n",
      "|    null|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQWYgKBMrbp"
   },
   "source": [
    "**Get the groupped_Embarked:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu46QWrn_gCX"
   },
   "outputs": [],
   "source": [
    "grouped=grouped_Embarked.head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8vhoEs8N2w_"
   },
   "source": [
    "**Fill missing values with grouped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdzQCRud_mAa"
   },
   "outputs": [],
   "source": [
    "new_df1=new_df1.na.fill(value=grouped,subset=[\"Embarked\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEcdV5Vb_qR_"
   },
   "source": [
    "## **Preprocessing Cabin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQzPs7tqhpA"
   },
   "source": [
    "**Replace \"cabin\" column with first char from the string:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh43GYerO6la"
   },
   "outputs": [],
   "source": [
    "def cabin_function(x):\n",
    "    if x is not None:\n",
    "       \n",
    "       x=x[0]\n",
    "       return x\n",
    "    \n",
    "\n",
    "convertUDF = udf(lambda x: cabin_function(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H8XshnYj4k2"
   },
   "source": [
    "**Show the result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJUQwnG1Oj2U"
   },
   "outputs": [],
   "source": [
    "new_df1=new_df1.withColumn('new_cabin',convertUDF(f.col(\"cabin\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzSDsWsUj9Im"
   },
   "source": [
    "**Create the temporary view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR7CXTY7_tMJ"
   },
   "outputs": [],
   "source": [
    "new_df1.createOrReplaceTempView(\"Temp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7lfQFkrLlN"
   },
   "source": [
    "**Select \"Cabin\" column, count Cabin column, Group by \"Cabin\" column, Order By count DESC**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0tZG_mvrKXv",
    "outputId": "68dc5da3-9583-4246-ebfa-8dfe4a4d7f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|new_cabin|count|\n",
      "+---------+-----+\n",
      "|     null| 1021|\n",
      "|        C|   82|\n",
      "|        B|   77|\n",
      "|        D|   52|\n",
      "|        E|   51|\n",
      "|        A|   23|\n",
      "|        F|   18|\n",
      "|        G|    4|\n",
      "|        T|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df1.select('new_cabin').groupBy('new_cabin').count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GR6j0LOsB4y"
   },
   "source": [
    "**Fill missing values with \"U\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwq5CHEz_up_"
   },
   "outputs": [],
   "source": [
    "new_df1=new_df1.na.fill(value='U',subset=[\"new_cabin\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD3KTZsdUfhD",
    "outputId": "64ce72a3-2407-4267-9acd-caee505d2ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+--------+------+----------+---------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Embarked| Title|New_Titles|new_cabin|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+--------+------+----------+---------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25|       S|    Mr|  not rare|        U|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|       C|   Mrs|  not rare|        C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925|       S|  Miss|  not rare|        U|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1|       S|   Mrs|  not rare|        C|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05|       S|    Mr|  not rare|        U|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583|       Q|    Mr|  not rare|        U|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|       S|    Mr|  not rare|        E|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075|       S|Master|  not rare|        U|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333|       S|   Mrs|  not rare|        U|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708|       C|   Mrs|  not rare|        U|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|       S|  Miss|  not rare|        G|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55|       S|  Miss|  not rare|        C|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05|       S|    Mr|  not rare|        U|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275|       S|    Mr|  not rare|        U|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542|       S|  Miss|  not rare|        U|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0|       S|   Mrs|  not rare|        U|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125|       Q|Master|  not rare|        U|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0|       S|    Mr|  not rare|        U|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0|       S|   Mrs|  not rare|        U|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225|       C|   Mrs|  not rare|        U|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+--------+------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[('PassengerId', 'int'), ('Survived', 'int'), ('Pclass', 'int'), ('Name', 'string'), ('Sex', 'string'), ('Age', 'double'), ('SibSp', 'int'), ('Parch', 'int'), ('Ticket', 'string'), ('Fare', 'double'), ('Embarked', 'string'), ('Title', 'string'), ('New_Titles', 'string'), ('new_cabin', 'string')]\n"
     ]
    }
   ],
   "source": [
    "def drop_null_columns(df):\n",
    "    \"\"\"\n",
    "    This function drops all columns which contain null values.\n",
    "    :param df: A PySpark DataFrame\n",
    "    \"\"\"\n",
    "    null_counts = df.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in null_counts.items() if v > 0]\n",
    "    df = df.drop(*to_drop)\n",
    "    return df\n",
    "\n",
    "\n",
    "last_df = drop_null_columns(new_df1)\n",
    "last_df.show()\n",
    "print(last_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaP7Cocy_1XC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpaabBHIF5Wc",
    "outputId": "2bc6c71f-81d4-4588-c727-6a7a2526e5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1094 rows in the training set, and 235 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = last_df.randomSplit([.8,.2],seed=42)\n",
    "print(f\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRnhA_5-0Hi4"
   },
   "source": [
    "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RIKlOX71GQ-"
   },
   "source": [
    "**StringIndexer(inputCol=None, outputCol=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c_Hf_b0R12"
   },
   "source": [
    "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsmfAFej9glb",
    "outputId": "7ddfef69-c1c9-4aad-a969-bd1461e19356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [field for (field,dataType) in trainDF.dtypes if ((dataType == 'string') & (field != 'Ticket')  & (field != 'Name'))]\n",
    "print(type(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yTE7kRU99fS"
   },
   "outputs": [],
   "source": [
    "indexOutput= [x + \"_Index\" for x in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBAzn9J099o9"
   },
   "outputs": [],
   "source": [
    "OneHotColumns = [x + \"_ OHE\" for x in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDCC0uIZ99rh"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler ,StringIndexer,OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itcWaEVm99t0"
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categorical_columns ,outputCols=indexOutput,handleInvalid='skip')\n",
    "onehotEncoder = OneHotEncoder(inputCols=indexOutput,outputCols=OneHotColumns)\n",
    "\n",
    "numericColumns  = [field for (field,dataType) in trainDF.dtypes if ((dataType == 'double') | (dataType =='int')) & ((field != 'PassengerId') &(field != 'Survived')) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0LhnQRyCLao"
   },
   "outputs": [],
   "source": [
    "assembler_Inputs = OneHotColumns + numericColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TW-QP4NSCZI9"
   },
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=assembler_Inputs , outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv7jXwvpCujT"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "random= RandomForestClassifier(labelCol='Survived',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m1b_RyCE_tC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzhrYEUSEBc1"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer,onehotEncoder,vecAssembler,random])\n",
    "pipeline_Model = pipeline.fit(trainDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X7NfLtZHQpN"
   },
   "outputs": [],
   "source": [
    "predictions = pipeline_Model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZly1vu8Hg9E",
    "outputId": "d39834a0-fa51-4957-dc4f-1d193d357f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|(32,[1,4,18,19,27...|       1|       0.0|\n",
      "|(32,[0,1,3,18,23,...|       0|       0.0|\n",
      "|(32,[1,5,18,19,27...|       1|       1.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[2,5,18,19,27...|       1|       1.0|\n",
      "|(32,[0,1,3,18,24,...|       1|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,3,18,19,27...|       0|       0.0|\n",
      "|(32,[4,18,19,27,2...|       1|       1.0|\n",
      "|(32,[1,5,18,19,27...|       0|       1.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,1,3,18,20,...|       1|       0.0|\n",
      "|(32,[0,1,3,18,20,...|       0|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[1,4,18,19,27...|       0|       0.0|\n",
      "|(32,[0,1,3,18,19,...|       0|       0.0|\n",
      "|(32,[0,3,18,19,27...|       0|       0.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('features','Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWfXaZ0I4dXD"
   },
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rl0UAKCaBDO-"
   },
   "outputs": [],
   "source": [
    " from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    " eval = MulticlassClassificationEvaluator(labelCol='Survived',predictionCol='prediction',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm6zgzgRJoik",
    "outputId": "43d8075c-5548-45b9-ca6f-d733ca56c7f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034188034188035"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ahmed Mamdouh - Practical_work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
